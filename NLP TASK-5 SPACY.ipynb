{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: spacy in c:\\users\\budem\\anaconda3\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (45.2.0.post20200210)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (4.42.1)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: thinc==7.4.1 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (7.4.1)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\budem\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\budem\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "Language\n",
      "Toolkit,\n",
      "or\n",
      "more\n",
      "commonly\n",
      "NLTK,\n",
      "is\n",
      "a\n",
      "suite\n",
      "of\n",
      "libraries\n",
      "and\n",
      "programs\n",
      "for\n",
      "symbolic\n",
      "and\n",
      "statistical\n",
      "natural\n",
      "language\n",
      "processing\n",
      "(NLP)\n",
      "for\n",
      "English\n",
      "written\n",
      "in\n",
      "the\n",
      "Python\n",
      "programming\n",
      "language.\n",
      "It\n",
      "was\n",
      "developed\n",
      "by\n",
      "Steven\n",
      "Bird\n",
      "and\n",
      "Edward\n",
      "Loper\n",
      "in\n",
      "the\n",
      "Department\n",
      "of\n",
      "Computer\n",
      "and\n",
      "Information\n",
      "Science\n",
      "at\n",
      "the\n",
      "University\n",
      "of\n",
      "Pennsylvania.\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "str = \"\"\"Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\"\"\"\n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "tokens = tokenizer(str)\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Toolkit"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "str = \"\"\"Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\"\"\"\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(str)\n",
    "doc[2]\n",
    "#doc[0].pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(NLTK, 'ORG', 383),\n",
       " (NLP, 'ORG', 383),\n",
       " (English, 'LANGUAGE', 389),\n",
       " (Steven Bird, 'PERSON', 380),\n",
       " (Edward Loper, 'PERSON', 380),\n",
       " (the Department of Computer and Information Science, 'ORG', 383),\n",
       " (the University of Pennsylvania, 'ORG', 383)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "str = \"\"\"Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\"\"\"\n",
    "doc = nlp(str)\n",
    "entities = [(i, i.label_, i.label) for i in doc.ents]\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPN',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'CCONJ',\n",
       " 'ADJ',\n",
       " 'ADV',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'AUX',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'NOUN',\n",
       " 'CCONJ',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'ADJ',\n",
       " 'CCONJ',\n",
       " 'ADJ',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'PUNCT',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'DET',\n",
       " 'PROPN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'PUNCT',\n",
       " 'PRON',\n",
       " 'AUX',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'CCONJ',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'ADP',\n",
       " 'DET',\n",
       " 'PROPN',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'CCONJ',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'ADP',\n",
       " 'DET',\n",
       " 'PROPN',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "str = \"\"\"Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\"\"\"\n",
    "doc = nlp(str)\n",
    "[token.pos_ for token in doc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "m = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"Google was founded in September 1998 by Larry Page and Sergey Brin while they were Ph.D students at Stanford University in California.Together they own about 14 percent of its shares and control 56 percent of the stockholder voting power through supervoting stock.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = m(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google ORG\n",
      "September 1998 DATE\n",
      "Larry Page PERSON\n",
      "Sergey Brin PERSON\n",
      "Stanford University ORG\n",
      "California GPE\n",
      "about 14 percent PERCENT\n",
      "56 percent PERCENT\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = [('Omnicom','IN','New York'),('DDB Needham','IN','New York'),('Kalpan Thaler Group','IN','New York'),('BBDO South','IN','Atlanta'),('Geaorgia-pacific','IN','Atlanta')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [e1 for (e1,rel,e2) in locs if e2 == 'Atlanta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BBDO South', 'Geaorgia-pacific']\n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"Founded in July 2003 by engineers Martin Eberhard and Marc Tarpenning as Tesla Motors, the companyâ€™s name is a tribute to inventor and electrical engineer Nikola Tesla. The next three employees were Ian Wright, Elon Musk, and J. B. Straubel, all of whom are named as co-founders of the company.[21] Musk, who formerly served as chairman and is the current CEO, said in 2006 that the overarching purpose of Tesla Motors...is to help expedite the move from a mine-and-burn hydrocarbon economy towards a solar electric economy and it would build a wide range of electric vehicles, including affordably priced family cars, and co-market SolarCity solar panels to do so. Tesla acquired SolarCity in 2016.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1= m(example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "July 2003 DATE\n",
      "Martin Eberhard PERSON\n",
      "Marc Tarpenning PERSON\n",
      "Tesla Motors ORG\n",
      "Nikola Tesla ORG\n",
      "three CARDINAL\n",
      "Ian Wright PERSON\n",
      "Elon Musk PERSON\n",
      "J. B. Straubel PERSON\n",
      "Musk PERSON\n",
      "2006 DATE\n",
      "Tesla Motors ORG\n",
      "SolarCity ORG\n",
      "Tesla ORDINAL\n",
      "SolarCity ORG\n",
      "2016 DATE\n"
     ]
    }
   ],
   "source": [
    "for ent in doc1.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
